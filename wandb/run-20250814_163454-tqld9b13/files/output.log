[34m[1mwandb[0m: [33mWARNING[0m Config item 'per_device_train_batch_size' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).
  0%|                                                                                                     | 0/3000 [00:00<?, ?it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                           | 500/3000 [01:05<06:00,  6.93it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 8.4268, 'grad_norm': 51.55387878417969, 'learning_rate': 6.069684464570754e-06, 'epoch': 0.07}
{'loss': 4.1415, 'grad_norm': 57.410282135009766, 'learning_rate': 1.226324004066336e-05, 'epoch': 0.13}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 2.5671310424804688, 'eval_accuracy': 0.3, 'eval_runtime': 0.5123, 'eval_samples_per_second': 195.204, 'eval_steps_per_second': 13.664, 'epoch': 0.13}
{'loss': 2.2957, 'grad_norm': 96.97724151611328, 'learning_rate': 1.8456795616755967e-05, 'epoch': 0.2}
{'loss': 2.0034, 'grad_norm': 51.145301818847656, 'learning_rate': 2.4650351192848575e-05, 'epoch': 0.27}
{'eval_loss': 1.7530860900878906, 'eval_accuracy': 0.37, 'eval_runtime': 0.4818, 'eval_samples_per_second': 207.577, 'eval_steps_per_second': 14.53, 'epoch': 0.27}
{'loss': 1.7406, 'grad_norm': 46.474327087402344, 'learning_rate': 3.084390676894118e-05, 'epoch': 0.33}
{'loss': 1.6165, 'grad_norm': 37.27281188964844, 'learning_rate': 3.7037462345033784e-05, 'epoch': 0.4}
{'eval_loss': 1.384783148765564, 'eval_accuracy': 0.49, 'eval_runtime': 0.6522, 'eval_samples_per_second': 153.333, 'eval_steps_per_second': 10.733, 'epoch': 0.4}
{'loss': 1.448, 'grad_norm': 47.468570709228516, 'learning_rate': 4.323101792112639e-05, 'epoch': 0.47}
{'loss': 1.448, 'grad_norm': 64.2173080444336, 'learning_rate': 4.9424573497219e-05, 'epoch': 0.53}
{'eval_loss': 1.267777919769287, 'eval_accuracy': 0.49, 'eval_runtime': 1.1044, 'eval_samples_per_second': 90.551, 'eval_steps_per_second': 6.339, 'epoch': 0.53}
{'loss': 1.3462, 'grad_norm': 65.49678039550781, 'learning_rate': 5.5618129073311604e-05, 'epoch': 0.6}
{'loss': 1.3854, 'grad_norm': 34.26530838012695, 'learning_rate': 6.181168464940422e-05, 'epoch': 0.67}
{'eval_loss': 1.1942164897918701, 'eval_accuracy': 0.55, 'eval_runtime': 0.7338, 'eval_samples_per_second': 136.275, 'eval_steps_per_second': 9.539, 'epoch': 0.67}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                            | 1000/3000 [02:20<03:29,  9.57it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 1.2557, 'grad_norm': 40.74344253540039, 'learning_rate': 6.800524022549681e-05, 'epoch': 0.73}
{'loss': 1.316, 'grad_norm': 47.90735626220703, 'learning_rate': 6.991506860198647e-05, 'epoch': 0.8}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 1.2750332355499268, 'eval_accuracy': 0.58, 'eval_runtime': 0.7148, 'eval_samples_per_second': 139.905, 'eval_steps_per_second': 9.793, 'epoch': 0.8}
{'loss': 1.2183, 'grad_norm': 50.09782028198242, 'learning_rate': 6.845911132164522e-05, 'epoch': 0.87}
{'loss': 1.1108, 'grad_norm': 45.61274337768555, 'learning_rate': 6.700315404130399e-05, 'epoch': 0.93}
{'eval_loss': 1.1915602684020996, 'eval_accuracy': 0.6, 'eval_runtime': 0.7293, 'eval_samples_per_second': 137.11, 'eval_steps_per_second': 9.598, 'epoch': 0.93}
{'loss': 1.1649, 'grad_norm': 34.60972595214844, 'learning_rate': 6.554719676096275e-05, 'epoch': 1.0}
{'loss': 0.8055, 'grad_norm': 43.954498291015625, 'learning_rate': 6.40912394806215e-05, 'epoch': 1.07}
{'eval_loss': 1.026349425315857, 'eval_accuracy': 0.6, 'eval_runtime': 0.7093, 'eval_samples_per_second': 140.984, 'eval_steps_per_second': 9.869, 'epoch': 1.07}
{'loss': 0.8814, 'grad_norm': 103.67993927001953, 'learning_rate': 6.263528220028026e-05, 'epoch': 1.13}
{'loss': 0.7818, 'grad_norm': 42.3936767578125, 'learning_rate': 6.117932491993902e-05, 'epoch': 1.2}
{'eval_loss': 1.242055892944336, 'eval_accuracy': 0.61, 'eval_runtime': 0.5508, 'eval_samples_per_second': 181.55, 'eval_steps_per_second': 12.708, 'epoch': 1.2}
{'loss': 0.7606, 'grad_norm': 31.572568893432617, 'learning_rate': 5.972336763959778e-05, 'epoch': 1.27}
{'loss': 0.7992, 'grad_norm': 28.345529556274414, 'learning_rate': 5.8267410359256534e-05, 'epoch': 1.33}
{'eval_loss': 1.0305535793304443, 'eval_accuracy': 0.63, 'eval_runtime': 0.5762, 'eval_samples_per_second': 173.564, 'eval_steps_per_second': 12.15, 'epoch': 1.33}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                           | 1007/3000 [02:21<04:35,  7.23it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                             | 1500/3000 [03:16<02:42,  9.21it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 0.7523, 'grad_norm': 90.61294555664062, 'learning_rate': 5.681145307891529e-05, 'epoch': 1.4}
{'loss': 0.7035, 'grad_norm': 56.32664489746094, 'learning_rate': 5.535549579857404e-05, 'epoch': 1.47}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 1.0707929134368896, 'eval_accuracy': 0.62, 'eval_runtime': 0.4882, 'eval_samples_per_second': 204.834, 'eval_steps_per_second': 14.338, 'epoch': 1.47}
{'loss': 0.6718, 'grad_norm': 9.612531661987305, 'learning_rate': 5.38995385182328e-05, 'epoch': 1.53}
{'loss': 0.7348, 'grad_norm': 31.643810272216797, 'learning_rate': 5.2443581237891556e-05, 'epoch': 1.6}
{'eval_loss': 0.9281964302062988, 'eval_accuracy': 0.67, 'eval_runtime': 0.4838, 'eval_samples_per_second': 206.691, 'eval_steps_per_second': 14.468, 'epoch': 1.6}
{'loss': 0.7937, 'grad_norm': 22.662202835083008, 'learning_rate': 5.098762395755031e-05, 'epoch': 1.67}
{'loss': 0.6588, 'grad_norm': 40.91722869873047, 'learning_rate': 4.953166667720907e-05, 'epoch': 1.73}
{'eval_loss': 0.8358503580093384, 'eval_accuracy': 0.72, 'eval_runtime': 0.5102, 'eval_samples_per_second': 195.986, 'eval_steps_per_second': 13.719, 'epoch': 1.73}
{'loss': 0.742, 'grad_norm': 33.96430969238281, 'learning_rate': 4.807570939686783e-05, 'epoch': 1.8}
{'loss': 0.7141, 'grad_norm': 47.063880920410156, 'learning_rate': 4.6619752116526586e-05, 'epoch': 1.87}
{'eval_loss': 0.9815857410430908, 'eval_accuracy': 0.7, 'eval_runtime': 0.5978, 'eval_samples_per_second': 167.276, 'eval_steps_per_second': 11.709, 'epoch': 1.87}
{'loss': 0.604, 'grad_norm': 16.907928466796875, 'learning_rate': 4.516379483618534e-05, 'epoch': 1.93}
{'loss': 0.6872, 'grad_norm': 35.78582000732422, 'learning_rate': 4.3707837555844104e-05, 'epoch': 2.0}
{'eval_loss': 0.869638204574585, 'eval_accuracy': 0.74, 'eval_runtime': 0.5599, 'eval_samples_per_second': 178.596, 'eval_steps_per_second': 12.502, 'epoch': 2.0}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                            | 1517/3000 [03:18<02:51,  8.65it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 2000/3000 [04:17<01:54,  8.74it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 0.2079, 'grad_norm': 9.94630241394043, 'learning_rate': 4.225188027550286e-05, 'epoch': 2.07}
{'loss': 0.2026, 'grad_norm': 33.13001251220703, 'learning_rate': 4.0795922995161615e-05, 'epoch': 2.13}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 1.0071179866790771, 'eval_accuracy': 0.73, 'eval_runtime': 0.5588, 'eval_samples_per_second': 178.964, 'eval_steps_per_second': 12.528, 'epoch': 2.13}
{'loss': 0.2022, 'grad_norm': 3.5302681922912598, 'learning_rate': 3.933996571482037e-05, 'epoch': 2.2}
{'loss': 0.2159, 'grad_norm': 5.0803961753845215, 'learning_rate': 3.7884008434479134e-05, 'epoch': 2.27}
{'eval_loss': 0.953591525554657, 'eval_accuracy': 0.71, 'eval_runtime': 0.6487, 'eval_samples_per_second': 154.144, 'eval_steps_per_second': 10.79, 'epoch': 2.27}
{'loss': 0.2036, 'grad_norm': 42.0833625793457, 'learning_rate': 3.642805115413789e-05, 'epoch': 2.33}
{'loss': 0.351, 'grad_norm': 7.578846454620361, 'learning_rate': 3.4972093873796645e-05, 'epoch': 2.4}
{'eval_loss': 1.0781866312026978, 'eval_accuracy': 0.73, 'eval_runtime': 0.5316, 'eval_samples_per_second': 188.11, 'eval_steps_per_second': 13.168, 'epoch': 2.4}
{'loss': 0.2293, 'grad_norm': 0.26357483863830566, 'learning_rate': 3.351613659345541e-05, 'epoch': 2.47}
{'loss': 0.2523, 'grad_norm': 2.0639450550079346, 'learning_rate': 3.206017931311416e-05, 'epoch': 2.53}
{'eval_loss': 0.9756701588630676, 'eval_accuracy': 0.77, 'eval_runtime': 0.528, 'eval_samples_per_second': 189.4, 'eval_steps_per_second': 13.258, 'epoch': 2.53}
{'loss': 0.2098, 'grad_norm': 34.415443420410156, 'learning_rate': 3.060422203277292e-05, 'epoch': 2.6}
{'loss': 0.2799, 'grad_norm': 15.4911470413208, 'learning_rate': 2.9148264752431678e-05, 'epoch': 2.67}
{'eval_loss': 1.1721339225769043, 'eval_accuracy': 0.72, 'eval_runtime': 0.6028, 'eval_samples_per_second': 165.895, 'eval_steps_per_second': 11.613, 'epoch': 2.67}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                       | 2013/3000 [04:18<02:03,  8.00it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 2500/3000 [05:21<00:57,  8.75it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 0.2378, 'grad_norm': 41.19704055786133, 'learning_rate': 2.7692307472090437e-05, 'epoch': 2.73}
{'loss': 0.2093, 'grad_norm': 45.22199249267578, 'learning_rate': 2.6236350191749193e-05, 'epoch': 2.8}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 0.9606053233146667, 'eval_accuracy': 0.76, 'eval_runtime': 0.5629, 'eval_samples_per_second': 177.644, 'eval_steps_per_second': 12.435, 'epoch': 2.8}
{'loss': 0.1981, 'grad_norm': 18.900615692138672, 'learning_rate': 2.478039291140795e-05, 'epoch': 2.87}
{'loss': 0.1627, 'grad_norm': 0.09865622967481613, 'learning_rate': 2.3324435631066707e-05, 'epoch': 2.93}
{'eval_loss': 0.9104573130607605, 'eval_accuracy': 0.79, 'eval_runtime': 0.5803, 'eval_samples_per_second': 172.326, 'eval_steps_per_second': 12.063, 'epoch': 2.93}
{'loss': 0.2448, 'grad_norm': 38.65241622924805, 'learning_rate': 2.1868478350725463e-05, 'epoch': 3.0}
{'loss': 0.0232, 'grad_norm': 28.85326385498047, 'learning_rate': 2.041252107038422e-05, 'epoch': 3.07}
{'eval_loss': 1.176052212715149, 'eval_accuracy': 0.74, 'eval_runtime': 0.6163, 'eval_samples_per_second': 162.261, 'eval_steps_per_second': 11.358, 'epoch': 3.07}
{'loss': 0.0188, 'grad_norm': 0.42535150051116943, 'learning_rate': 1.8956563790042978e-05, 'epoch': 3.13}
{'loss': 0.0452, 'grad_norm': 0.13197080790996552, 'learning_rate': 1.7500606509701737e-05, 'epoch': 3.2}
{'eval_loss': 1.1360795497894287, 'eval_accuracy': 0.75, 'eval_runtime': 0.7825, 'eval_samples_per_second': 127.796, 'eval_steps_per_second': 8.946, 'epoch': 3.2}
{'loss': 0.0428, 'grad_norm': 1.5797076225280762, 'learning_rate': 1.6044649229360492e-05, 'epoch': 3.27}
{'loss': 0.0223, 'grad_norm': 0.13196630775928497, 'learning_rate': 1.458869194901925e-05, 'epoch': 3.33}
{'eval_loss': 1.2522166967391968, 'eval_accuracy': 0.73, 'eval_runtime': 0.5811, 'eval_samples_per_second': 172.08, 'eval_steps_per_second': 12.046, 'epoch': 3.33}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž           | 2505/3000 [05:22<01:30,  5.44it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3000/3000 [06:39<00:00,  6.87it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 0.0331, 'grad_norm': 8.849308967590332, 'learning_rate': 1.3132734668678009e-05, 'epoch': 3.4}
{'loss': 0.0233, 'grad_norm': 0.005954214371740818, 'learning_rate': 1.1676777388336766e-05, 'epoch': 3.47}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 1.1821701526641846, 'eval_accuracy': 0.76, 'eval_runtime': 0.6941, 'eval_samples_per_second': 144.066, 'eval_steps_per_second': 10.085, 'epoch': 3.47}
{'loss': 0.0204, 'grad_norm': 0.013689134269952774, 'learning_rate': 1.0220820107995524e-05, 'epoch': 3.53}
{'loss': 0.0363, 'grad_norm': 32.609073638916016, 'learning_rate': 8.764862827654281e-06, 'epoch': 3.6}
{'eval_loss': 1.2095855474472046, 'eval_accuracy': 0.74, 'eval_runtime': 0.7384, 'eval_samples_per_second': 135.433, 'eval_steps_per_second': 9.48, 'epoch': 3.6}
{'loss': 0.0338, 'grad_norm': 0.15423278510570526, 'learning_rate': 7.3089055473130375e-06, 'epoch': 3.67}
{'loss': 0.0269, 'grad_norm': 0.031416118144989014, 'learning_rate': 5.852948266971796e-06, 'epoch': 3.73}
{'eval_loss': 1.1785944700241089, 'eval_accuracy': 0.77, 'eval_runtime': 0.8953, 'eval_samples_per_second': 111.69, 'eval_steps_per_second': 7.818, 'epoch': 3.73}
{'loss': 0.0232, 'grad_norm': 0.06302118301391602, 'learning_rate': 4.396990986630552e-06, 'epoch': 3.8}
{'loss': 0.0183, 'grad_norm': 0.21915851533412933, 'learning_rate': 2.9410337062893104e-06, 'epoch': 3.87}
{'eval_loss': 1.172054409980774, 'eval_accuracy': 0.76, 'eval_runtime': 0.7517, 'eval_samples_per_second': 133.037, 'eval_steps_per_second': 9.313, 'epoch': 3.87}
{'loss': 0.044, 'grad_norm': 3.8487448692321777, 'learning_rate': 1.4850764259480674e-06, 'epoch': 3.93}
{'loss': 0.0229, 'grad_norm': 0.2159586399793625, 'learning_rate': 2.9119145606824853e-08, 'epoch': 4.0}
{'eval_loss': 1.1834306716918945, 'eval_accuracy': 0.75, 'eval_runtime': 0.7014, 'eval_samples_per_second': 142.564, 'eval_steps_per_second': 9.979, 'epoch': 4.0}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3000/3000 [06:39<00:00,  7.50it/s]
{'train_runtime': 403.9474, 'train_samples_per_second': 59.414, 'train_steps_per_second': 7.427, 'train_loss': 0.780844852010409, 'epoch': 4.0}
