[34m[1mwandb[0m: [33mWARNING[0m Config item 'per_device_train_batch_size' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).
  0%|                                                                                  | 0/1875 [00:00<?, ?it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                    | 500/1875 [01:55<05:47,  3.96it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 7.8416, 'grad_norm': 42.334815979003906, 'learning_rate': 8.10923030897841e-06, 'epoch': 0.13}
{'loss': 3.1481, 'grad_norm': 46.1734733581543, 'learning_rate': 1.6383955114058426e-05, 'epoch': 0.27}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 1.9698563814163208, 'eval_accuracy': 0.36, 'eval_runtime': 0.5098, 'eval_samples_per_second': 196.151, 'eval_steps_per_second': 13.731, 'epoch': 0.27}
{'loss': 1.8164, 'grad_norm': 29.514636993408203, 'learning_rate': 2.4658679919138437e-05, 'epoch': 0.4}
{'loss': 1.5744, 'grad_norm': 69.47219848632812, 'learning_rate': 3.2933404724218445e-05, 'epoch': 0.53}
{'eval_loss': 1.4462225437164307, 'eval_accuracy': 0.42, 'eval_runtime': 0.5128, 'eval_samples_per_second': 195.006, 'eval_steps_per_second': 13.65, 'epoch': 0.53}
{'loss': 1.4469, 'grad_norm': 41.89445495605469, 'learning_rate': 4.1208129529298456e-05, 'epoch': 0.67}
{'loss': 1.337, 'grad_norm': 22.635547637939453, 'learning_rate': 4.948285433437847e-05, 'epoch': 0.8}
{'eval_loss': 1.1058943271636963, 'eval_accuracy': 0.63, 'eval_runtime': 0.4789, 'eval_samples_per_second': 208.792, 'eval_steps_per_second': 14.615, 'epoch': 0.8}
{'loss': 1.1869, 'grad_norm': 42.10256576538086, 'learning_rate': 5.7757579139458486e-05, 'epoch': 0.93}
{'loss': 1.0637, 'grad_norm': 29.15667724609375, 'learning_rate': 5.84439492406069e-05, 'epoch': 1.07}
{'eval_loss': 1.1147525310516357, 'eval_accuracy': 0.6, 'eval_runtime': 0.8789, 'eval_samples_per_second': 113.774, 'eval_steps_per_second': 7.964, 'epoch': 1.07}
{'loss': 0.9349, 'grad_norm': 29.417287826538086, 'learning_rate': 5.646414066199555e-05, 'epoch': 1.2}
{'loss': 0.8708, 'grad_norm': 29.296836853027344, 'learning_rate': 5.4484332083384204e-05, 'epoch': 1.33}
{'eval_loss': 1.0597783327102661, 'eval_accuracy': 0.61, 'eval_runtime': 0.7308, 'eval_samples_per_second': 136.831, 'eval_steps_per_second': 9.578, 'epoch': 1.33}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                    | 504/1875 [01:57<09:28,  2.41it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                 | 1000/1875 [03:42<02:50,  5.12it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 0.7747, 'grad_norm': 43.27728271484375, 'learning_rate': 5.250452350477286e-05, 'epoch': 1.47}
{'loss': 0.8055, 'grad_norm': 23.303585052490234, 'learning_rate': 5.052471492616152e-05, 'epoch': 1.6}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 0.7646971940994263, 'eval_accuracy': 0.7, 'eval_runtime': 0.5099, 'eval_samples_per_second': 196.106, 'eval_steps_per_second': 13.727, 'epoch': 1.6}
{'loss': 0.8005, 'grad_norm': 23.312931060791016, 'learning_rate': 4.8544906347550174e-05, 'epoch': 1.73}
{'loss': 0.7681, 'grad_norm': 33.375892639160156, 'learning_rate': 4.6565097768938825e-05, 'epoch': 1.87}
{'eval_loss': 0.889078676700592, 'eval_accuracy': 0.7, 'eval_runtime': 0.4751, 'eval_samples_per_second': 210.472, 'eval_steps_per_second': 14.733, 'epoch': 1.87}
{'loss': 0.677, 'grad_norm': 23.385971069335938, 'learning_rate': 4.458528919032748e-05, 'epoch': 2.0}
{'loss': 0.2601, 'grad_norm': 17.69697380065918, 'learning_rate': 4.260548061171614e-05, 'epoch': 2.13}
{'eval_loss': 0.8617123365402222, 'eval_accuracy': 0.74, 'eval_runtime': 0.4878, 'eval_samples_per_second': 205.001, 'eval_steps_per_second': 14.35, 'epoch': 2.13}
{'loss': 0.2484, 'grad_norm': 8.689987182617188, 'learning_rate': 4.0625672033104795e-05, 'epoch': 2.27}
{'loss': 0.2949, 'grad_norm': 21.683181762695312, 'learning_rate': 3.8645863454493445e-05, 'epoch': 2.4}
{'eval_loss': 0.8356401324272156, 'eval_accuracy': 0.78, 'eval_runtime': 0.5555, 'eval_samples_per_second': 180.01, 'eval_steps_per_second': 12.601, 'epoch': 2.4}
{'loss': 0.262, 'grad_norm': 14.434488296508789, 'learning_rate': 3.66660548758821e-05, 'epoch': 2.53}
{'loss': 0.2805, 'grad_norm': 18.264047622680664, 'learning_rate': 3.468624629727076e-05, 'epoch': 2.67}
{'eval_loss': 0.9250251650810242, 'eval_accuracy': 0.74, 'eval_runtime': 0.5415, 'eval_samples_per_second': 184.672, 'eval_steps_per_second': 12.927, 'epoch': 2.67}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š              | 1500/1875 [05:25<01:10,  5.33it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 0.2532, 'grad_norm': 15.769294738769531, 'learning_rate': 3.2706437718659416e-05, 'epoch': 2.8}
{'loss': 0.1943, 'grad_norm': 9.133808135986328, 'learning_rate': 3.0726629140048066e-05, 'epoch': 2.93}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 0.7516553401947021, 'eval_accuracy': 0.8, 'eval_runtime': 0.508, 'eval_samples_per_second': 196.835, 'eval_steps_per_second': 13.778, 'epoch': 2.93}
{'loss': 0.172, 'grad_norm': 16.22083282470703, 'learning_rate': 2.8746820561436723e-05, 'epoch': 3.07}
{'loss': 0.079, 'grad_norm': 1.1885647773742676, 'learning_rate': 2.676701198282538e-05, 'epoch': 3.2}
{'eval_loss': 0.836853563785553, 'eval_accuracy': 0.76, 'eval_runtime': 0.5833, 'eval_samples_per_second': 171.451, 'eval_steps_per_second': 12.002, 'epoch': 3.2}
{'loss': 0.0438, 'grad_norm': 36.969486236572266, 'learning_rate': 2.4787203404214033e-05, 'epoch': 3.33}
{'loss': 0.0343, 'grad_norm': 0.03906300291419029, 'learning_rate': 2.280739482560269e-05, 'epoch': 3.47}
{'eval_loss': 1.1952532529830933, 'eval_accuracy': 0.75, 'eval_runtime': 0.51, 'eval_samples_per_second': 196.081, 'eval_steps_per_second': 13.726, 'epoch': 3.47}
{'loss': 0.0504, 'grad_norm': 26.253828048706055, 'learning_rate': 2.0827586246991343e-05, 'epoch': 3.6}
{'loss': 0.0724, 'grad_norm': 0.4233568608760834, 'learning_rate': 1.884777766838e-05, 'epoch': 3.73}
{'eval_loss': 1.0905359983444214, 'eval_accuracy': 0.75, 'eval_runtime': 0.5322, 'eval_samples_per_second': 187.884, 'eval_steps_per_second': 13.152, 'epoch': 3.73}
{'loss': 0.028, 'grad_norm': 8.852510452270508, 'learning_rate': 1.6867969089768654e-05, 'epoch': 3.87}
{'loss': 0.0342, 'grad_norm': 1.613891363143921, 'learning_rate': 1.488816051115731e-05, 'epoch': 4.0}
{'eval_loss': 1.0209723711013794, 'eval_accuracy': 0.81, 'eval_runtime': 0.4977, 'eval_samples_per_second': 200.922, 'eval_steps_per_second': 14.065, 'epoch': 4.0}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹             | 1524/1875 [05:30<01:12,  4.85it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1875/1875 [06:49<00:00,  4.43it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 0.0143, 'grad_norm': 0.09143777191638947, 'learning_rate': 1.2908351932545967e-05, 'epoch': 4.13}
{'loss': 0.0059, 'grad_norm': 0.39634931087493896, 'learning_rate': 1.0928543353934623e-05, 'epoch': 4.27}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 1.0459996461868286, 'eval_accuracy': 0.8, 'eval_runtime': 0.5734, 'eval_samples_per_second': 174.398, 'eval_steps_per_second': 12.208, 'epoch': 4.27}
{'loss': 0.0066, 'grad_norm': 0.30558696389198303, 'learning_rate': 8.948734775323278e-06, 'epoch': 4.4}
{'loss': 0.0019, 'grad_norm': 0.5842395424842834, 'learning_rate': 6.968926196711933e-06, 'epoch': 4.53}
{'eval_loss': 1.0684449672698975, 'eval_accuracy': 0.79, 'eval_runtime': 0.5154, 'eval_samples_per_second': 194.013, 'eval_steps_per_second': 13.581, 'epoch': 4.53}
{'loss': 0.0034, 'grad_norm': 0.10860981792211533, 'learning_rate': 4.989117618100589e-06, 'epoch': 4.67}
{'loss': 0.0067, 'grad_norm': 0.04115661606192589, 'learning_rate': 3.0093090394892437e-06, 'epoch': 4.8}
{'eval_loss': 1.0412920713424683, 'eval_accuracy': 0.76, 'eval_runtime': 0.7257, 'eval_samples_per_second': 137.79, 'eval_steps_per_second': 9.645, 'epoch': 4.8}
{'loss': 0.0014, 'grad_norm': 0.3571172058582306, 'learning_rate': 1.0295004608778993e-06, 'epoch': 4.93}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1875/1875 [06:49<00:00,  4.57it/s]
{'train_runtime': 414.1648, 'train_samples_per_second': 72.435, 'train_steps_per_second': 4.527, 'train_loss': 0.7305244273811579, 'epoch': 5.0}
