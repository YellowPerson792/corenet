[34m[1mwandb[0m: [33mWARNING[0m Config item 'per_device_train_batch_size' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).
  0%|                                                                                  | 0/3750 [00:00<?, ?it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                              | 500/3750 [01:13<07:37,  7.11it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 5.3097, 'grad_norm': 45.47185516357422, 'learning_rate': 6.228796002955432e-05, 'epoch': 0.07}
{'loss': 2.036, 'grad_norm': 36.10056686401367, 'learning_rate': 0.00012584710291685462, 'epoch': 0.13}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 1.660830020904541, 'eval_accuracy': 0.4, 'eval_runtime': 0.5272, 'eval_samples_per_second': 189.699, 'eval_steps_per_second': 13.279, 'epoch': 0.13}
{'loss': 1.8814, 'grad_norm': 24.179704666137695, 'learning_rate': 0.00018940624580415493, 'epoch': 0.2}
{'loss': 1.8563, 'grad_norm': 16.588096618652344, 'learning_rate': 0.00018677633403236716, 'epoch': 0.27}
{'eval_loss': 1.8550848960876465, 'eval_accuracy': 0.35, 'eval_runtime': 0.7555, 'eval_samples_per_second': 132.367, 'eval_steps_per_second': 9.266, 'epoch': 0.27}
{'loss': 1.6443, 'grad_norm': 21.929784774780273, 'learning_rate': 0.0001841464222605794, 'epoch': 0.33}
{'loss': 1.6412, 'grad_norm': 20.32724380493164, 'learning_rate': 0.00018151651048879162, 'epoch': 0.4}
{'eval_loss': 1.5086482763290405, 'eval_accuracy': 0.5, 'eval_runtime': 0.7145, 'eval_samples_per_second': 139.96, 'eval_steps_per_second': 9.797, 'epoch': 0.4}
{'loss': 1.5432, 'grad_norm': 26.966930389404297, 'learning_rate': 0.00017888659871700388, 'epoch': 0.47}
{'loss': 1.5437, 'grad_norm': 27.336462020874023, 'learning_rate': 0.0001762566869452161, 'epoch': 0.53}
{'eval_loss': 1.3464428186416626, 'eval_accuracy': 0.46, 'eval_runtime': 0.693, 'eval_samples_per_second': 144.303, 'eval_steps_per_second': 10.101, 'epoch': 0.53}
{'loss': 1.4636, 'grad_norm': 17.339569091796875, 'learning_rate': 0.00017362677517342834, 'epoch': 0.6}
{'loss': 1.4139, 'grad_norm': 12.623525619506836, 'learning_rate': 0.00017099686340164058, 'epoch': 0.67}
{'eval_loss': 1.1841846704483032, 'eval_accuracy': 0.6, 'eval_runtime': 0.6853, 'eval_samples_per_second': 145.917, 'eval_steps_per_second': 10.214, 'epoch': 0.67}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                    | 1000/3750 [02:28<06:20,  7.22it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 1.4019, 'grad_norm': 20.739992141723633, 'learning_rate': 0.00016836695162985278, 'epoch': 0.73}
{'loss': 1.4315, 'grad_norm': 20.79246711730957, 'learning_rate': 0.000165737039858065, 'epoch': 0.8}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 1.2571039199829102, 'eval_accuracy': 0.56, 'eval_runtime': 0.6509, 'eval_samples_per_second': 153.642, 'eval_steps_per_second': 10.755, 'epoch': 0.8}
{'loss': 1.3976, 'grad_norm': 23.552196502685547, 'learning_rate': 0.00016310712808627724, 'epoch': 0.87}
{'loss': 1.3973, 'grad_norm': 29.018310546875, 'learning_rate': 0.0001604772163144895, 'epoch': 0.93}
{'eval_loss': 1.3967634439468384, 'eval_accuracy': 0.49, 'eval_runtime': 0.6726, 'eval_samples_per_second': 148.672, 'eval_steps_per_second': 10.407, 'epoch': 0.93}
{'loss': 1.3828, 'grad_norm': 23.267518997192383, 'learning_rate': 0.00015784730454270173, 'epoch': 1.0}
{'loss': 0.9605, 'grad_norm': 34.612083435058594, 'learning_rate': 0.00015521739277091397, 'epoch': 1.07}
{'eval_loss': 1.0472264289855957, 'eval_accuracy': 0.61, 'eval_runtime': 0.6514, 'eval_samples_per_second': 153.517, 'eval_steps_per_second': 10.746, 'epoch': 1.07}
{'loss': 1.0141, 'grad_norm': 38.627681732177734, 'learning_rate': 0.0001525874809991262, 'epoch': 1.13}
{'loss': 1.0237, 'grad_norm': 21.38676643371582, 'learning_rate': 0.00014995756922733843, 'epoch': 1.2}
{'eval_loss': 1.3028661012649536, 'eval_accuracy': 0.57, 'eval_runtime': 0.6453, 'eval_samples_per_second': 154.959, 'eval_steps_per_second': 10.847, 'epoch': 1.2}
{'loss': 0.9474, 'grad_norm': 29.221712112426758, 'learning_rate': 0.00014732765745555066, 'epoch': 1.27}
{'loss': 1.0355, 'grad_norm': 20.8176326751709, 'learning_rate': 0.0001446977456837629, 'epoch': 1.33}
{'eval_loss': 1.1226537227630615, 'eval_accuracy': 0.59, 'eval_runtime': 0.6693, 'eval_samples_per_second': 149.419, 'eval_steps_per_second': 10.459, 'epoch': 1.33}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                    | 1007/3750 [02:29<08:43,  5.24it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                          | 1500/3750 [03:41<04:49,  7.78it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 1.0201, 'grad_norm': 44.64805221557617, 'learning_rate': 0.00014206783391197512, 'epoch': 1.4}
{'loss': 0.9708, 'grad_norm': 31.137880325317383, 'learning_rate': 0.00013943792214018738, 'epoch': 1.47}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 1.2919312715530396, 'eval_accuracy': 0.52, 'eval_runtime': 0.6576, 'eval_samples_per_second': 152.068, 'eval_steps_per_second': 10.645, 'epoch': 1.47}
{'loss': 0.93, 'grad_norm': 31.566078186035156, 'learning_rate': 0.00013680801036839962, 'epoch': 1.53}
{'loss': 0.8769, 'grad_norm': 15.264677047729492, 'learning_rate': 0.00013417809859661185, 'epoch': 1.6}
{'eval_loss': 0.9822519421577454, 'eval_accuracy': 0.59, 'eval_runtime': 0.6425, 'eval_samples_per_second': 155.63, 'eval_steps_per_second': 10.894, 'epoch': 1.6}
{'loss': 1.0107, 'grad_norm': 12.549873352050781, 'learning_rate': 0.00013154818682482405, 'epoch': 1.67}
{'loss': 0.9778, 'grad_norm': 35.05827331542969, 'learning_rate': 0.00012891827505303628, 'epoch': 1.73}
{'eval_loss': 1.1743099689483643, 'eval_accuracy': 0.61, 'eval_runtime': 0.6411, 'eval_samples_per_second': 155.974, 'eval_steps_per_second': 10.918, 'epoch': 1.73}
{'loss': 1.0205, 'grad_norm': 35.50794982910156, 'learning_rate': 0.00012628836328124852, 'epoch': 1.8}
{'loss': 0.9853, 'grad_norm': 32.86339569091797, 'learning_rate': 0.00012365845150946077, 'epoch': 1.87}
{'eval_loss': 1.0819448232650757, 'eval_accuracy': 0.61, 'eval_runtime': 0.6601, 'eval_samples_per_second': 151.486, 'eval_steps_per_second': 10.604, 'epoch': 1.87}
{'loss': 0.9338, 'grad_norm': 15.364307403564453, 'learning_rate': 0.00012102853973767299, 'epoch': 1.93}
{'loss': 0.9247, 'grad_norm': 18.995677947998047, 'learning_rate': 0.00011839862796588524, 'epoch': 2.0}
{'eval_loss': 1.120999813079834, 'eval_accuracy': 0.62, 'eval_runtime': 0.6514, 'eval_samples_per_second': 153.504, 'eval_steps_per_second': 10.745, 'epoch': 2.0}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                          | 1517/3750 [03:44<05:10,  7.18it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                 | 2000/3750 [04:55<03:57,  7.38it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 0.4528, 'grad_norm': 7.9679059982299805, 'learning_rate': 0.00011576871619409747, 'epoch': 2.07}
{'loss': 0.5008, 'grad_norm': 31.023038864135742, 'learning_rate': 0.0001131388044223097, 'epoch': 2.13}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 1.3783977031707764, 'eval_accuracy': 0.62, 'eval_runtime': 0.6517, 'eval_samples_per_second': 153.443, 'eval_steps_per_second': 10.741, 'epoch': 2.13}
{'loss': 0.5163, 'grad_norm': 17.829463958740234, 'learning_rate': 0.00011050889265052193, 'epoch': 2.2}
{'loss': 0.4911, 'grad_norm': 57.292457580566406, 'learning_rate': 0.00010787898087873418, 'epoch': 2.27}
{'eval_loss': 1.8802810907363892, 'eval_accuracy': 0.62, 'eval_runtime': 0.6896, 'eval_samples_per_second': 145.007, 'eval_steps_per_second': 10.15, 'epoch': 2.27}
{'loss': 0.5691, 'grad_norm': 27.710237503051758, 'learning_rate': 0.00010524906910694641, 'epoch': 2.33}
{'loss': 0.5679, 'grad_norm': 31.548608779907227, 'learning_rate': 0.00010261915733515864, 'epoch': 2.4}
{'eval_loss': 1.4624170064926147, 'eval_accuracy': 0.6, 'eval_runtime': 0.69, 'eval_samples_per_second': 144.917, 'eval_steps_per_second': 10.144, 'epoch': 2.4}
{'loss': 0.4908, 'grad_norm': 11.955633163452148, 'learning_rate': 9.998924556337087e-05, 'epoch': 2.47}
{'loss': 0.4787, 'grad_norm': 54.65786361694336, 'learning_rate': 9.735933379158312e-05, 'epoch': 2.53}
{'eval_loss': 1.2629414796829224, 'eval_accuracy': 0.67, 'eval_runtime': 0.6709, 'eval_samples_per_second': 149.05, 'eval_steps_per_second': 10.434, 'epoch': 2.53}
{'loss': 0.5477, 'grad_norm': 19.48268699645996, 'learning_rate': 9.472942201979535e-05, 'epoch': 2.6}
{'loss': 0.6335, 'grad_norm': 43.65115737915039, 'learning_rate': 9.209951024800757e-05, 'epoch': 2.67}
{'eval_loss': 1.3993853330612183, 'eval_accuracy': 0.58, 'eval_runtime': 0.6536, 'eval_samples_per_second': 152.989, 'eval_steps_per_second': 10.709, 'epoch': 2.67}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                 | 2013/3750 [04:57<04:11,  6.92it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 2500/3750 [05:54<02:17,  9.10it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 0.4799, 'grad_norm': 8.565462112426758, 'learning_rate': 8.946959847621981e-05, 'epoch': 2.73}
{'loss': 0.475, 'grad_norm': 24.31061363220215, 'learning_rate': 8.683968670443205e-05, 'epoch': 2.8}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 1.2533525228500366, 'eval_accuracy': 0.59, 'eval_runtime': 0.4967, 'eval_samples_per_second': 201.324, 'eval_steps_per_second': 14.093, 'epoch': 2.8}
{'loss': 0.4966, 'grad_norm': 36.12733840942383, 'learning_rate': 8.420977493264426e-05, 'epoch': 2.87}
{'loss': 0.4899, 'grad_norm': 40.21281051635742, 'learning_rate': 8.157986316085651e-05, 'epoch': 2.93}
{'eval_loss': 1.3464503288269043, 'eval_accuracy': 0.62, 'eval_runtime': 0.4993, 'eval_samples_per_second': 200.296, 'eval_steps_per_second': 14.021, 'epoch': 2.93}
{'loss': 0.5586, 'grad_norm': 26.457862854003906, 'learning_rate': 7.894995138906874e-05, 'epoch': 3.0}
{'loss': 0.1799, 'grad_norm': 48.42338180541992, 'learning_rate': 7.632003961728097e-05, 'epoch': 3.07}
{'eval_loss': 1.233557939529419, 'eval_accuracy': 0.75, 'eval_runtime': 0.5021, 'eval_samples_per_second': 199.152, 'eval_steps_per_second': 13.941, 'epoch': 3.07}
{'loss': 0.1985, 'grad_norm': 51.7302131652832, 'learning_rate': 7.36901278454932e-05, 'epoch': 3.13}
{'loss': 0.226, 'grad_norm': 0.8536602854728699, 'learning_rate': 7.106021607370545e-05, 'epoch': 3.2}
{'eval_loss': 1.5172717571258545, 'eval_accuracy': 0.74, 'eval_runtime': 0.5078, 'eval_samples_per_second': 196.943, 'eval_steps_per_second': 13.786, 'epoch': 3.2}
{'loss': 0.2624, 'grad_norm': 2.9917657375335693, 'learning_rate': 6.843030430191768e-05, 'epoch': 3.27}
{'loss': 0.2635, 'grad_norm': 63.837257385253906, 'learning_rate': 6.580039253012991e-05, 'epoch': 3.33}
{'eval_loss': 1.6001530885696411, 'eval_accuracy': 0.71, 'eval_runtime': 0.5374, 'eval_samples_per_second': 186.074, 'eval_steps_per_second': 13.025, 'epoch': 3.33}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 2505/3750 [05:54<03:33,  5.83it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š              | 3000/3750 [06:50<01:23,  9.02it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 0.206, 'grad_norm': 77.76368713378906, 'learning_rate': 6.317048075834215e-05, 'epoch': 3.4}
{'loss': 0.2244, 'grad_norm': 19.067110061645508, 'learning_rate': 6.054056898655438e-05, 'epoch': 3.47}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 1.450210452079773, 'eval_accuracy': 0.69, 'eval_runtime': 0.5089, 'eval_samples_per_second': 196.495, 'eval_steps_per_second': 13.755, 'epoch': 3.47}
{'loss': 0.2421, 'grad_norm': 79.94988250732422, 'learning_rate': 5.791065721476661e-05, 'epoch': 3.53}
{'loss': 0.2026, 'grad_norm': 116.86398315429688, 'learning_rate': 5.528074544297885e-05, 'epoch': 3.6}
{'eval_loss': 1.70745050907135, 'eval_accuracy': 0.74, 'eval_runtime': 0.5139, 'eval_samples_per_second': 194.589, 'eval_steps_per_second': 13.621, 'epoch': 3.6}
{'loss': 0.1683, 'grad_norm': 17.329980850219727, 'learning_rate': 5.265083367119108e-05, 'epoch': 3.67}
{'loss': 0.313, 'grad_norm': 0.4285367727279663, 'learning_rate': 5.002092189940332e-05, 'epoch': 3.73}
{'eval_loss': 1.84051513671875, 'eval_accuracy': 0.64, 'eval_runtime': 0.5217, 'eval_samples_per_second': 191.664, 'eval_steps_per_second': 13.417, 'epoch': 3.73}
{'loss': 0.1586, 'grad_norm': 92.67179870605469, 'learning_rate': 4.739101012761555e-05, 'epoch': 3.8}
{'loss': 0.2635, 'grad_norm': 0.4791000485420227, 'learning_rate': 4.476109835582778e-05, 'epoch': 3.87}
{'eval_loss': 1.7594915628433228, 'eval_accuracy': 0.72, 'eval_runtime': 0.5209, 'eval_samples_per_second': 191.98, 'eval_steps_per_second': 13.439, 'epoch': 3.87}
{'loss': 0.2015, 'grad_norm': 66.7975082397461, 'learning_rate': 4.213118658404002e-05, 'epoch': 3.93}
{'loss': 0.1492, 'grad_norm': 1.565747857093811, 'learning_rate': 3.9501274812252246e-05, 'epoch': 4.0}
{'eval_loss': 1.5816943645477295, 'eval_accuracy': 0.74, 'eval_runtime': 0.5143, 'eval_samples_per_second': 194.454, 'eval_steps_per_second': 13.612, 'epoch': 4.0}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 3018/3750 [06:52<01:19,  9.25it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3500/3750 [07:47<00:26,  9.59it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 0.0761, 'grad_norm': 66.99321746826172, 'learning_rate': 3.6871363040464485e-05, 'epoch': 4.07}
{'loss': 0.0625, 'grad_norm': 0.03203389421105385, 'learning_rate': 3.4241451268676716e-05, 'epoch': 4.13}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 1.8388876914978027, 'eval_accuracy': 0.73, 'eval_runtime': 0.5445, 'eval_samples_per_second': 183.66, 'eval_steps_per_second': 12.856, 'epoch': 4.13}
{'loss': 0.0225, 'grad_norm': 0.005809368100017309, 'learning_rate': 3.161153949688895e-05, 'epoch': 4.2}
{'loss': 0.0519, 'grad_norm': 12.063372611999512, 'learning_rate': 2.8981627725101183e-05, 'epoch': 4.27}
{'eval_loss': 1.7850637435913086, 'eval_accuracy': 0.78, 'eval_runtime': 0.5251, 'eval_samples_per_second': 190.449, 'eval_steps_per_second': 13.331, 'epoch': 4.27}
{'loss': 0.0123, 'grad_norm': 0.24953900277614594, 'learning_rate': 2.635171595331342e-05, 'epoch': 4.33}
{'loss': 0.0171, 'grad_norm': 8.381922816624865e-05, 'learning_rate': 2.3721804181525654e-05, 'epoch': 4.4}
{'eval_loss': 1.94284987449646, 'eval_accuracy': 0.73, 'eval_runtime': 0.5354, 'eval_samples_per_second': 186.785, 'eval_steps_per_second': 13.075, 'epoch': 4.4}
{'loss': 0.0245, 'grad_norm': 0.008236379362642765, 'learning_rate': 2.1091892409737885e-05, 'epoch': 4.47}
{'loss': 0.0297, 'grad_norm': 0.022248173132538795, 'learning_rate': 1.8461980637950117e-05, 'epoch': 4.53}
{'eval_loss': 1.8630915880203247, 'eval_accuracy': 0.76, 'eval_runtime': 0.512, 'eval_samples_per_second': 195.317, 'eval_steps_per_second': 13.672, 'epoch': 4.53}
{'loss': 0.0294, 'grad_norm': 114.57708740234375, 'learning_rate': 1.5832068866162352e-05, 'epoch': 4.6}
{'loss': 0.0333, 'grad_norm': 0.352498859167099, 'learning_rate': 1.3202157094374586e-05, 'epoch': 4.67}
{'eval_loss': 1.8663432598114014, 'eval_accuracy': 0.73, 'eval_runtime': 0.526, 'eval_samples_per_second': 190.111, 'eval_steps_per_second': 13.308, 'epoch': 4.67}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3520/3750 [07:49<00:25,  9.12it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3750/3750 [08:15<00:00,  9.36it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 0.0058, 'grad_norm': 0.0024257462937384844, 'learning_rate': 1.0572245322586821e-05, 'epoch': 4.73}
{'loss': 0.0171, 'grad_norm': 59.153079986572266, 'learning_rate': 7.942333550799055e-06, 'epoch': 4.8}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 1.929176688194275, 'eval_accuracy': 0.79, 'eval_runtime': 0.5334, 'eval_samples_per_second': 187.472, 'eval_steps_per_second': 13.123, 'epoch': 4.8}
{'loss': 0.0104, 'grad_norm': 0.001824456499889493, 'learning_rate': 5.312421779011288e-06, 'epoch': 4.87}
{'loss': 0.0339, 'grad_norm': 0.0008733763825148344, 'learning_rate': 2.6825100072235215e-06, 'epoch': 4.93}
{'eval_loss': 1.9119482040405273, 'eval_accuracy': 0.78, 'eval_runtime': 0.5455, 'eval_samples_per_second': 183.327, 'eval_steps_per_second': 12.833, 'epoch': 4.93}
{'loss': 0.0064, 'grad_norm': 0.005033643916249275, 'learning_rate': 5.259823543575533e-08, 'epoch': 5.0}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3750/3750 [08:16<00:00,  7.56it/s]
{'train_runtime': 501.0895, 'train_samples_per_second': 59.87, 'train_steps_per_second': 7.484, 'train_loss': 0.7122374504009883, 'epoch': 5.0}
