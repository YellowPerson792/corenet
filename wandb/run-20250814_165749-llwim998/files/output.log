[34m[1mwandb[0m: [33mWARNING[0m Config item 'per_device_train_batch_size' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).
  0%|                                                                                  | 0/1875 [00:00<?, ?it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                    | 500/1875 [01:42<04:35,  5.00it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 4.6294, 'grad_norm': 43.80561828613281, 'learning_rate': 7.821290385585515e-05, 'epoch': 0.13}
{'loss': 1.9637, 'grad_norm': 18.417800903320312, 'learning_rate': 0.00014627219415586987, 'epoch': 0.27}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 1.6236982345581055, 'eval_accuracy': 0.43, 'eval_runtime': 0.5501, 'eval_samples_per_second': 181.775, 'eval_steps_per_second': 12.724, 'epoch': 0.27}
{'loss': 1.5107, 'grad_norm': 21.996368408203125, 'learning_rate': 0.00014215417067175193, 'epoch': 0.4}
{'loss': 1.352, 'grad_norm': 18.854219436645508, 'learning_rate': 0.00013803614718763395, 'epoch': 0.53}
{'eval_loss': 1.3013010025024414, 'eval_accuracy': 0.51, 'eval_runtime': 0.5373, 'eval_samples_per_second': 186.109, 'eval_steps_per_second': 13.028, 'epoch': 0.53}
{'loss': 1.2595, 'grad_norm': 17.95967674255371, 'learning_rate': 0.000133918123703516, 'epoch': 0.67}
{'loss': 1.1516, 'grad_norm': 25.904375076293945, 'learning_rate': 0.00012980010021939803, 'epoch': 0.8}
{'eval_loss': 1.0190849304199219, 'eval_accuracy': 0.67, 'eval_runtime': 0.5373, 'eval_samples_per_second': 186.109, 'eval_steps_per_second': 13.028, 'epoch': 0.8}
{'loss': 1.0703, 'grad_norm': 26.627899169921875, 'learning_rate': 0.00012568207673528008, 'epoch': 0.93}
{'loss': 0.8806, 'grad_norm': 23.978015899658203, 'learning_rate': 0.00012156405325116214, 'epoch': 1.07}
{'eval_loss': 0.8948853015899658, 'eval_accuracy': 0.75, 'eval_runtime': 0.5575, 'eval_samples_per_second': 179.381, 'eval_steps_per_second': 12.557, 'epoch': 1.07}
{'loss': 0.7353, 'grad_norm': 16.452560424804688, 'learning_rate': 0.00011744602976704418, 'epoch': 1.2}
{'loss': 0.6614, 'grad_norm': 25.349458694458008, 'learning_rate': 0.0001133280062829262, 'epoch': 1.33}
{'eval_loss': 1.0457347631454468, 'eval_accuracy': 0.67, 'eval_runtime': 0.547, 'eval_samples_per_second': 182.828, 'eval_steps_per_second': 12.798, 'epoch': 1.33}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                    | 504/1875 [01:44<06:47,  3.36it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                 | 1000/1875 [03:26<02:57,  4.92it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 0.6525, 'grad_norm': 27.579587936401367, 'learning_rate': 0.00010920998279880824, 'epoch': 1.47}
{'loss': 0.689, 'grad_norm': 17.75741958618164, 'learning_rate': 0.00010509195931469031, 'epoch': 1.6}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 0.8806930780410767, 'eval_accuracy': 0.72, 'eval_runtime': 0.5435, 'eval_samples_per_second': 183.995, 'eval_steps_per_second': 12.88, 'epoch': 1.6}
{'loss': 0.6277, 'grad_norm': 21.98590087890625, 'learning_rate': 0.00010097393583057233, 'epoch': 1.73}
{'loss': 0.6732, 'grad_norm': 24.79644012451172, 'learning_rate': 9.685591234645437e-05, 'epoch': 1.87}
{'eval_loss': 0.9926256537437439, 'eval_accuracy': 0.69, 'eval_runtime': 0.5671, 'eval_samples_per_second': 176.341, 'eval_steps_per_second': 12.344, 'epoch': 1.87}
{'loss': 0.6113, 'grad_norm': 26.969335556030273, 'learning_rate': 9.273788886233641e-05, 'epoch': 2.0}
{'loss': 0.2387, 'grad_norm': 28.372739791870117, 'learning_rate': 8.861986537821845e-05, 'epoch': 2.13}
{'eval_loss': 1.0905084609985352, 'eval_accuracy': 0.69, 'eval_runtime': 0.5554, 'eval_samples_per_second': 180.059, 'eval_steps_per_second': 12.604, 'epoch': 2.13}
{'loss': 0.2298, 'grad_norm': 24.020954132080078, 'learning_rate': 8.45018418941005e-05, 'epoch': 2.27}
{'loss': 0.2777, 'grad_norm': 27.81532096862793, 'learning_rate': 8.038381840998254e-05, 'epoch': 2.4}
{'eval_loss': 0.896344780921936, 'eval_accuracy': 0.77, 'eval_runtime': 0.5454, 'eval_samples_per_second': 183.35, 'eval_steps_per_second': 12.834, 'epoch': 2.4}
{'loss': 0.2302, 'grad_norm': 23.10776138305664, 'learning_rate': 7.626579492586458e-05, 'epoch': 2.53}
{'loss': 0.265, 'grad_norm': 39.614952087402344, 'learning_rate': 7.214777144174662e-05, 'epoch': 2.67}
{'eval_loss': 1.123631477355957, 'eval_accuracy': 0.73, 'eval_runtime': 0.6059, 'eval_samples_per_second': 165.052, 'eval_steps_per_second': 11.554, 'epoch': 2.67}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š              | 1500/1875 [05:11<01:11,  5.25it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 0.2408, 'grad_norm': 6.68710470199585, 'learning_rate': 6.802974795762868e-05, 'epoch': 2.8}
{'loss': 0.156, 'grad_norm': 10.780021667480469, 'learning_rate': 6.391172447351072e-05, 'epoch': 2.93}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 1.0015645027160645, 'eval_accuracy': 0.75, 'eval_runtime': 0.5828, 'eval_samples_per_second': 171.577, 'eval_steps_per_second': 12.01, 'epoch': 2.93}
{'loss': 0.1665, 'grad_norm': 5.2435736656188965, 'learning_rate': 5.9793700989392755e-05, 'epoch': 3.07}
{'loss': 0.0785, 'grad_norm': 13.15418815612793, 'learning_rate': 5.5675677505274794e-05, 'epoch': 3.2}
{'eval_loss': 1.15224289894104, 'eval_accuracy': 0.69, 'eval_runtime': 0.5837, 'eval_samples_per_second': 171.325, 'eval_steps_per_second': 11.993, 'epoch': 3.2}
{'loss': 0.0763, 'grad_norm': 2.010921001434326, 'learning_rate': 5.1557654021156833e-05, 'epoch': 3.33}
{'loss': 0.0479, 'grad_norm': 49.07404708862305, 'learning_rate': 4.743963053703888e-05, 'epoch': 3.47}
{'eval_loss': 1.6468256711959839, 'eval_accuracy': 0.72, 'eval_runtime': 0.5866, 'eval_samples_per_second': 170.485, 'eval_steps_per_second': 11.934, 'epoch': 3.47}
{'loss': 0.078, 'grad_norm': 7.912278652191162, 'learning_rate': 4.332160705292092e-05, 'epoch': 3.6}
{'loss': 0.0637, 'grad_norm': 51.746646881103516, 'learning_rate': 3.9203583568802965e-05, 'epoch': 3.73}
{'eval_loss': 1.4627799987792969, 'eval_accuracy': 0.72, 'eval_runtime': 0.5781, 'eval_samples_per_second': 172.975, 'eval_steps_per_second': 12.108, 'epoch': 3.73}
{'loss': 0.066, 'grad_norm': 0.969366192817688, 'learning_rate': 3.5085560084685004e-05, 'epoch': 3.87}
{'loss': 0.0387, 'grad_norm': 21.17886734008789, 'learning_rate': 3.0967536600567044e-05, 'epoch': 4.0}
{'eval_loss': 1.5368947982788086, 'eval_accuracy': 0.74, 'eval_runtime': 0.5808, 'eval_samples_per_second': 172.178, 'eval_steps_per_second': 12.052, 'epoch': 4.0}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹             | 1524/1875 [05:16<01:11,  4.93it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1875/1875 [06:28<00:00,  5.10it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 0.0095, 'grad_norm': 0.03461163118481636, 'learning_rate': 2.684951311644909e-05, 'epoch': 4.13}
{'loss': 0.0228, 'grad_norm': 0.11149001121520996, 'learning_rate': 2.273148963233113e-05, 'epoch': 4.27}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 1.4778854846954346, 'eval_accuracy': 0.76, 'eval_runtime': 0.5429, 'eval_samples_per_second': 184.197, 'eval_steps_per_second': 12.894, 'epoch': 4.27}
{'loss': 0.0082, 'grad_norm': 0.6781129837036133, 'learning_rate': 1.861346614821317e-05, 'epoch': 4.4}
{'loss': 0.001, 'grad_norm': 0.010051754303276539, 'learning_rate': 1.4495442664095213e-05, 'epoch': 4.53}
{'eval_loss': 1.4962178468704224, 'eval_accuracy': 0.75, 'eval_runtime': 0.5548, 'eval_samples_per_second': 180.261, 'eval_steps_per_second': 12.618, 'epoch': 4.53}
{'loss': 0.0052, 'grad_norm': 0.07205244153738022, 'learning_rate': 1.0377419179977254e-05, 'epoch': 4.67}
{'loss': 0.0119, 'grad_norm': 0.01919008418917656, 'learning_rate': 6.259395695859297e-06, 'epoch': 4.8}
{'eval_loss': 1.501840353012085, 'eval_accuracy': 0.73, 'eval_runtime': 0.5573, 'eval_samples_per_second': 179.423, 'eval_steps_per_second': 12.56, 'epoch': 4.8}
{'loss': 0.0039, 'grad_norm': 3.78747296333313, 'learning_rate': 2.141372211741338e-06, 'epoch': 4.93}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1875/1875 [06:28<00:00,  4.82it/s]
{'train_runtime': 392.7458, 'train_samples_per_second': 76.385, 'train_steps_per_second': 4.774, 'train_loss': 0.5542714227368434, 'epoch': 5.0}
