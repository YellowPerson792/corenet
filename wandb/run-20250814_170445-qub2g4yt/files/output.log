[34m[1mwandb[0m: [33mWARNING[0m Config item 'per_device_train_batch_size' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'num_train_epochs' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).
  0%|                                                                                  | 0/3750 [00:00<?, ?it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                              | 500/3750 [00:59<06:15,  8.66it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 3.4424, 'grad_norm': 15.92279052734375, 'learning_rate': 0.00023714595480393464, 'epoch': 0.07}
{'loss': 2.3423, 'grad_norm': 16.699495315551758, 'learning_rate': 0.000233942145633387, 'epoch': 0.13}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 2.2890055179595947, 'eval_accuracy': 0.15, 'eval_runtime': 0.5367, 'eval_samples_per_second': 186.308, 'eval_steps_per_second': 13.042, 'epoch': 0.13}
{'loss': 2.2051, 'grad_norm': 10.418296813964844, 'learning_rate': 0.0002307383364628394, 'epoch': 0.2}
{'loss': 2.1462, 'grad_norm': 8.11617660522461, 'learning_rate': 0.00022753452729229177, 'epoch': 0.27}
{'eval_loss': 1.9836066961288452, 'eval_accuracy': 0.23, 'eval_runtime': 0.514, 'eval_samples_per_second': 194.544, 'eval_steps_per_second': 13.618, 'epoch': 0.27}
{'loss': 2.0858, 'grad_norm': 12.76319408416748, 'learning_rate': 0.00022433071812174416, 'epoch': 0.33}
{'loss': 2.0459, 'grad_norm': 12.476655960083008, 'learning_rate': 0.00022112690895119655, 'epoch': 0.4}
{'eval_loss': 1.9035978317260742, 'eval_accuracy': 0.34, 'eval_runtime': 0.5317, 'eval_samples_per_second': 188.071, 'eval_steps_per_second': 13.165, 'epoch': 0.4}
{'loss': 2.0003, 'grad_norm': 16.2055606842041, 'learning_rate': 0.0002179230997806489, 'epoch': 0.47}
{'loss': 2.024, 'grad_norm': 13.207167625427246, 'learning_rate': 0.0002147192906101013, 'epoch': 0.53}
{'eval_loss': 2.002624034881592, 'eval_accuracy': 0.23, 'eval_runtime': 0.5578, 'eval_samples_per_second': 179.265, 'eval_steps_per_second': 12.549, 'epoch': 0.53}
{'loss': 1.9306, 'grad_norm': 10.076809883117676, 'learning_rate': 0.0002115154814395537, 'epoch': 0.6}
{'loss': 2.0017, 'grad_norm': 8.299914360046387, 'learning_rate': 0.00020831167226900607, 'epoch': 0.67}
{'eval_loss': 1.8742402791976929, 'eval_accuracy': 0.29, 'eval_runtime': 0.5487, 'eval_samples_per_second': 182.262, 'eval_steps_per_second': 12.758, 'epoch': 0.67}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                    | 1000/3750 [01:59<05:13,  8.79it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 1.849, 'grad_norm': 9.778143882751465, 'learning_rate': 0.00020510786309845845, 'epoch': 0.73}
{'loss': 2.0006, 'grad_norm': 13.615384101867676, 'learning_rate': 0.0002019040539279108, 'epoch': 0.8}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 1.8799363374710083, 'eval_accuracy': 0.37, 'eval_runtime': 0.5603, 'eval_samples_per_second': 178.484, 'eval_steps_per_second': 12.494, 'epoch': 0.8}
{'loss': 2.0237, 'grad_norm': 16.317798614501953, 'learning_rate': 0.0001987002447573632, 'epoch': 0.87}
{'loss': 1.8697, 'grad_norm': 9.869019508361816, 'learning_rate': 0.0001954964355868156, 'epoch': 0.93}
{'eval_loss': 1.848897099494934, 'eval_accuracy': 0.29, 'eval_runtime': 0.5496, 'eval_samples_per_second': 181.935, 'eval_steps_per_second': 12.735, 'epoch': 0.93}
{'loss': 1.9228, 'grad_norm': 10.268553733825684, 'learning_rate': 0.00019229262641626797, 'epoch': 1.0}
{'loss': 1.714, 'grad_norm': 20.22842025756836, 'learning_rate': 0.00018908881724572036, 'epoch': 1.07}
{'eval_loss': 1.8314545154571533, 'eval_accuracy': 0.35, 'eval_runtime': 0.5556, 'eval_samples_per_second': 179.992, 'eval_steps_per_second': 12.599, 'epoch': 1.07}
{'loss': 1.836, 'grad_norm': 27.744014739990234, 'learning_rate': 0.00018588500807517275, 'epoch': 1.13}
{'loss': 1.6975, 'grad_norm': 11.635919570922852, 'learning_rate': 0.00018268119890462513, 'epoch': 1.2}
{'eval_loss': 1.8546568155288696, 'eval_accuracy': 0.28, 'eval_runtime': 0.5443, 'eval_samples_per_second': 183.729, 'eval_steps_per_second': 12.861, 'epoch': 1.2}
{'loss': 1.764, 'grad_norm': 15.826675415039062, 'learning_rate': 0.00017947738973407752, 'epoch': 1.27}
{'loss': 1.8463, 'grad_norm': 7.547647476196289, 'learning_rate': 0.00017627358056352988, 'epoch': 1.33}
{'eval_loss': 1.7294508218765259, 'eval_accuracy': 0.4, 'eval_runtime': 0.5402, 'eval_samples_per_second': 185.109, 'eval_steps_per_second': 12.958, 'epoch': 1.33}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                    | 1007/3750 [02:00<06:30,  7.03it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                          | 1500/3750 [02:59<04:11,  8.96it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 1.7183, 'grad_norm': 15.920287132263184, 'learning_rate': 0.00017306977139298227, 'epoch': 1.4}
{'loss': 1.6966, 'grad_norm': 13.675396919250488, 'learning_rate': 0.00016986596222243468, 'epoch': 1.47}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 1.851266622543335, 'eval_accuracy': 0.22, 'eval_runtime': 0.5542, 'eval_samples_per_second': 180.442, 'eval_steps_per_second': 12.631, 'epoch': 1.47}
{'loss': 1.7358, 'grad_norm': 14.562492370605469, 'learning_rate': 0.00016666215305188704, 'epoch': 1.53}
{'loss': 1.6937, 'grad_norm': 10.806800842285156, 'learning_rate': 0.00016345834388133943, 'epoch': 1.6}
{'eval_loss': 1.8358837366104126, 'eval_accuracy': 0.3, 'eval_runtime': 0.5463, 'eval_samples_per_second': 183.055, 'eval_steps_per_second': 12.814, 'epoch': 1.6}
{'loss': 1.746, 'grad_norm': 10.340394973754883, 'learning_rate': 0.0001602545347107918, 'epoch': 1.67}
{'loss': 1.7095, 'grad_norm': 10.377574920654297, 'learning_rate': 0.0001570507255402442, 'epoch': 1.73}
{'eval_loss': 1.8279069662094116, 'eval_accuracy': 0.33, 'eval_runtime': 0.5685, 'eval_samples_per_second': 175.908, 'eval_steps_per_second': 12.314, 'epoch': 1.73}
{'loss': 1.8644, 'grad_norm': 14.134905815124512, 'learning_rate': 0.00015384691636969659, 'epoch': 1.8}
{'loss': 1.7402, 'grad_norm': 18.09523582458496, 'learning_rate': 0.00015064310719914895, 'epoch': 1.87}
{'eval_loss': 1.8013180494308472, 'eval_accuracy': 0.31, 'eval_runtime': 0.552, 'eval_samples_per_second': 181.175, 'eval_steps_per_second': 12.682, 'epoch': 1.87}
{'loss': 1.7374, 'grad_norm': 8.905536651611328, 'learning_rate': 0.00014743929802860133, 'epoch': 1.93}
{'loss': 1.6627, 'grad_norm': 15.67043399810791, 'learning_rate': 0.00014423548885805375, 'epoch': 2.0}
{'eval_loss': 1.6062599420547485, 'eval_accuracy': 0.41, 'eval_runtime': 0.5386, 'eval_samples_per_second': 185.665, 'eval_steps_per_second': 12.997, 'epoch': 2.0}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                          | 1517/3750 [03:01<04:09,  8.95it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                 | 2000/3750 [03:59<03:11,  9.14it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 1.3606, 'grad_norm': 14.64581298828125, 'learning_rate': 0.0001410316796875061, 'epoch': 2.07}
{'loss': 1.3445, 'grad_norm': 13.824104309082031, 'learning_rate': 0.0001378278705169585, 'epoch': 2.13}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 1.8264917135238647, 'eval_accuracy': 0.33, 'eval_runtime': 0.5597, 'eval_samples_per_second': 178.677, 'eval_steps_per_second': 12.507, 'epoch': 2.13}
{'loss': 1.4468, 'grad_norm': 15.022482872009277, 'learning_rate': 0.00013462406134641085, 'epoch': 2.2}
{'loss': 1.4594, 'grad_norm': 25.598613739013672, 'learning_rate': 0.00013142025217586327, 'epoch': 2.27}
{'eval_loss': 1.7886337041854858, 'eval_accuracy': 0.38, 'eval_runtime': 0.5466, 'eval_samples_per_second': 182.936, 'eval_steps_per_second': 12.806, 'epoch': 2.27}
{'loss': 1.4222, 'grad_norm': 16.282638549804688, 'learning_rate': 0.00012821644300531565, 'epoch': 2.33}
{'loss': 1.3692, 'grad_norm': 15.530561447143555, 'learning_rate': 0.000125012633834768, 'epoch': 2.4}
{'eval_loss': 2.038947820663452, 'eval_accuracy': 0.32, 'eval_runtime': 0.5484, 'eval_samples_per_second': 182.353, 'eval_steps_per_second': 12.765, 'epoch': 2.4}
{'loss': 1.3188, 'grad_norm': 20.445669174194336, 'learning_rate': 0.0001218088246642204, 'epoch': 2.47}
{'loss': 1.3811, 'grad_norm': 11.20173168182373, 'learning_rate': 0.00011860501549367279, 'epoch': 2.53}
{'eval_loss': 1.645604133605957, 'eval_accuracy': 0.4, 'eval_runtime': 0.553, 'eval_samples_per_second': 180.843, 'eval_steps_per_second': 12.659, 'epoch': 2.53}
{'loss': 1.2953, 'grad_norm': 21.11235809326172, 'learning_rate': 0.00011540120632312516, 'epoch': 2.6}
{'loss': 1.4857, 'grad_norm': 19.311717987060547, 'learning_rate': 0.00011219739715257756, 'epoch': 2.67}
{'eval_loss': 1.5879286527633667, 'eval_accuracy': 0.43, 'eval_runtime': 0.5568, 'eval_samples_per_second': 179.597, 'eval_steps_per_second': 12.572, 'epoch': 2.67}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                 | 2013/3750 [04:01<03:18,  8.76it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 2500/3750 [04:59<02:26,  8.54it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 1.4006, 'grad_norm': 18.205480575561523, 'learning_rate': 0.00010899358798202993, 'epoch': 2.73}
{'loss': 1.4289, 'grad_norm': 17.50762939453125, 'learning_rate': 0.00010578977881148232, 'epoch': 2.8}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 1.7865934371948242, 'eval_accuracy': 0.29, 'eval_runtime': 0.5471, 'eval_samples_per_second': 182.769, 'eval_steps_per_second': 12.794, 'epoch': 2.8}
{'loss': 1.368, 'grad_norm': 19.020366668701172, 'learning_rate': 0.00010258596964093469, 'epoch': 2.87}
{'loss': 1.3193, 'grad_norm': 17.203838348388672, 'learning_rate': 9.938216047038709e-05, 'epoch': 2.93}
{'eval_loss': 1.6538383960723877, 'eval_accuracy': 0.39, 'eval_runtime': 0.5592, 'eval_samples_per_second': 178.831, 'eval_steps_per_second': 12.518, 'epoch': 2.93}
{'loss': 1.3662, 'grad_norm': 17.472476959228516, 'learning_rate': 9.617835129983946e-05, 'epoch': 3.0}
{'loss': 1.0275, 'grad_norm': 26.395957946777344, 'learning_rate': 9.297454212929185e-05, 'epoch': 3.07}
{'eval_loss': 2.010929822921753, 'eval_accuracy': 0.36, 'eval_runtime': 0.5485, 'eval_samples_per_second': 182.309, 'eval_steps_per_second': 12.762, 'epoch': 3.07}
{'loss': 0.9333, 'grad_norm': 23.806560516357422, 'learning_rate': 8.977073295874422e-05, 'epoch': 3.13}
{'loss': 0.9831, 'grad_norm': 22.130199432373047, 'learning_rate': 8.656692378819661e-05, 'epoch': 3.2}
{'eval_loss': 2.06391978263855, 'eval_accuracy': 0.35, 'eval_runtime': 0.5431, 'eval_samples_per_second': 184.112, 'eval_steps_per_second': 12.888, 'epoch': 3.2}
{'loss': 0.9441, 'grad_norm': 6.909127235412598, 'learning_rate': 8.3363114617649e-05, 'epoch': 3.27}
{'loss': 0.9436, 'grad_norm': 28.12333106994629, 'learning_rate': 8.015930544710138e-05, 'epoch': 3.33}
{'eval_loss': 2.022773265838623, 'eval_accuracy': 0.37, 'eval_runtime': 0.5559, 'eval_samples_per_second': 179.893, 'eval_steps_per_second': 12.593, 'epoch': 3.33}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 2505/3750 [05:00<03:45,  5.53it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š              | 3000/3750 [05:58<01:23,  8.99it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 0.892, 'grad_norm': 29.983428955078125, 'learning_rate': 7.695549627655376e-05, 'epoch': 3.4}
{'loss': 0.8859, 'grad_norm': 30.335330963134766, 'learning_rate': 7.375168710600614e-05, 'epoch': 3.47}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 2.11086368560791, 'eval_accuracy': 0.32, 'eval_runtime': 0.5418, 'eval_samples_per_second': 184.557, 'eval_steps_per_second': 12.919, 'epoch': 3.47}
{'loss': 0.9255, 'grad_norm': 55.05583953857422, 'learning_rate': 7.054787793545853e-05, 'epoch': 3.53}
{'loss': 0.8678, 'grad_norm': 28.41448211669922, 'learning_rate': 6.734406876491092e-05, 'epoch': 3.6}
{'eval_loss': 2.121957778930664, 'eval_accuracy': 0.36, 'eval_runtime': 0.5826, 'eval_samples_per_second': 171.632, 'eval_steps_per_second': 12.014, 'epoch': 3.6}
{'loss': 0.8719, 'grad_norm': 38.09046173095703, 'learning_rate': 6.414025959436329e-05, 'epoch': 3.67}
{'loss': 0.9538, 'grad_norm': 14.466324806213379, 'learning_rate': 6.0936450423815685e-05, 'epoch': 3.73}
{'eval_loss': 1.965932011604309, 'eval_accuracy': 0.41, 'eval_runtime': 0.5647, 'eval_samples_per_second': 177.091, 'eval_steps_per_second': 12.396, 'epoch': 3.73}
{'loss': 0.8154, 'grad_norm': 24.535985946655273, 'learning_rate': 5.773264125326806e-05, 'epoch': 3.8}
{'loss': 0.8681, 'grad_norm': 32.21743392944336, 'learning_rate': 5.4528832082720444e-05, 'epoch': 3.87}
{'eval_loss': 2.0722708702087402, 'eval_accuracy': 0.34, 'eval_runtime': 0.5353, 'eval_samples_per_second': 186.804, 'eval_steps_per_second': 13.076, 'epoch': 3.87}
{'loss': 0.8507, 'grad_norm': 33.13386917114258, 'learning_rate': 5.1325022912172824e-05, 'epoch': 3.93}
{'loss': 0.8297, 'grad_norm': 25.02238655090332, 'learning_rate': 4.812121374162521e-05, 'epoch': 4.0}
{'eval_loss': 2.1512482166290283, 'eval_accuracy': 0.37, 'eval_runtime': 0.5337, 'eval_samples_per_second': 187.36, 'eval_steps_per_second': 13.115, 'epoch': 4.0}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 3018/3750 [06:01<01:23,  8.78it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3500/3750 [06:58<00:28,  8.69it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 0.4098, 'grad_norm': 30.310585021972656, 'learning_rate': 4.491740457107759e-05, 'epoch': 4.07}
{'loss': 0.4322, 'grad_norm': 14.955412864685059, 'learning_rate': 4.171359540052998e-05, 'epoch': 4.13}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 3.1253180503845215, 'eval_accuracy': 0.35, 'eval_runtime': 0.5518, 'eval_samples_per_second': 181.23, 'eval_steps_per_second': 12.686, 'epoch': 4.13}
{'loss': 0.4629, 'grad_norm': 18.850427627563477, 'learning_rate': 3.850978622998236e-05, 'epoch': 4.2}
{'loss': 0.3932, 'grad_norm': 27.28853988647461, 'learning_rate': 3.5305977059434744e-05, 'epoch': 4.27}
{'eval_loss': 3.1788079738616943, 'eval_accuracy': 0.33, 'eval_runtime': 0.5543, 'eval_samples_per_second': 180.413, 'eval_steps_per_second': 12.629, 'epoch': 4.27}
{'loss': 0.4238, 'grad_norm': 40.934326171875, 'learning_rate': 3.2102167888887124e-05, 'epoch': 4.33}
{'loss': 0.3099, 'grad_norm': 97.39457702636719, 'learning_rate': 2.8898358718339507e-05, 'epoch': 4.4}
{'eval_loss': 3.7645952701568604, 'eval_accuracy': 0.36, 'eval_runtime': 0.5422, 'eval_samples_per_second': 184.428, 'eval_steps_per_second': 12.91, 'epoch': 4.4}
{'loss': 0.3771, 'grad_norm': 2.699601888656616, 'learning_rate': 2.569454954779189e-05, 'epoch': 4.47}
{'loss': 0.3327, 'grad_norm': 2.563394546508789, 'learning_rate': 2.2490740377244274e-05, 'epoch': 4.53}
{'eval_loss': 3.478178024291992, 'eval_accuracy': 0.35, 'eval_runtime': 0.573, 'eval_samples_per_second': 174.533, 'eval_steps_per_second': 12.217, 'epoch': 4.53}
{'loss': 0.3679, 'grad_norm': 12.763596534729004, 'learning_rate': 1.9286931206696654e-05, 'epoch': 4.6}
{'loss': 0.3339, 'grad_norm': 36.5203742980957, 'learning_rate': 1.6083122036149037e-05, 'epoch': 4.67}
{'eval_loss': 3.7858686447143555, 'eval_accuracy': 0.34, 'eval_runtime': 0.5515, 'eval_samples_per_second': 181.31, 'eval_steps_per_second': 12.692, 'epoch': 4.67}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3520/3750 [07:01<00:25,  8.96it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3750/3750 [07:28<00:00,  9.09it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 0.3333, 'grad_norm': 61.647762298583984, 'learning_rate': 1.2879312865601422e-05, 'epoch': 4.73}
{'loss': 0.3702, 'grad_norm': 60.51630783081055, 'learning_rate': 9.675503695053802e-06, 'epoch': 4.8}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 3.5199196338653564, 'eval_accuracy': 0.38, 'eval_runtime': 0.5613, 'eval_samples_per_second': 178.157, 'eval_steps_per_second': 12.471, 'epoch': 4.8}
{'loss': 0.3927, 'grad_norm': 1.2618521451950073, 'learning_rate': 6.471694524506187e-06, 'epoch': 4.87}
{'loss': 0.3996, 'grad_norm': 10.035277366638184, 'learning_rate': 3.2678853539585696e-06, 'epoch': 4.93}
{'eval_loss': 3.562241792678833, 'eval_accuracy': 0.38, 'eval_runtime': 0.5401, 'eval_samples_per_second': 185.142, 'eval_steps_per_second': 12.96, 'epoch': 4.93}
{'loss': 0.2635, 'grad_norm': 8.703923225402832, 'learning_rate': 6.407618341095234e-08, 'epoch': 5.0}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3750/3750 [07:28<00:00,  8.36it/s]
{'train_runtime': 453.0406, 'train_samples_per_second': 66.219, 'train_steps_per_second': 8.277, 'train_loss': 1.3068560722351075, 'epoch': 5.0}
