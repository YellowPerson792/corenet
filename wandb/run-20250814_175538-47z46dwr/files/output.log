  0%|                                                                                  | 0/3750 [00:00<?, ?it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 13%|█████████▌                                                              | 500/3750 [01:16<07:49,  6.93it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 5.2513, 'grad_norm': 44.87636947631836, 'learning_rate': 6.533333333333334e-05, 'epoch': 0.07}
{'loss': 2.0406, 'grad_norm': 34.78191375732422, 'learning_rate': 0.000132, 'epoch': 0.13}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 1.67023503780365, 'eval_accuracy': 0.37, 'eval_runtime': 0.7265, 'eval_samples_per_second': 137.648, 'eval_steps_per_second': 9.635, 'epoch': 0.13}
{'loss': 1.8252, 'grad_norm': 32.26760482788086, 'learning_rate': 0.00019866666666666668, 'epoch': 0.2}
{'loss': 1.8921, 'grad_norm': 17.69431495666504, 'learning_rate': 0.00019727777777777777, 'epoch': 0.27}
{'eval_loss': 1.7415422201156616, 'eval_accuracy': 0.34, 'eval_runtime': 0.6816, 'eval_samples_per_second': 146.72, 'eval_steps_per_second': 10.27, 'epoch': 0.27}
{'loss': 1.7417, 'grad_norm': 25.272632598876953, 'learning_rate': 0.0001945, 'epoch': 0.33}
{'loss': 1.795, 'grad_norm': 28.884380340576172, 'learning_rate': 0.00019172222222222222, 'epoch': 0.4}
{'eval_loss': 1.8353523015975952, 'eval_accuracy': 0.43, 'eval_runtime': 0.5432, 'eval_samples_per_second': 184.094, 'eval_steps_per_second': 12.887, 'epoch': 0.4}
{'loss': 1.5583, 'grad_norm': 28.44415283203125, 'learning_rate': 0.00018894444444444446, 'epoch': 0.47}
{'loss': 1.5878, 'grad_norm': 32.149513244628906, 'learning_rate': 0.00018616666666666667, 'epoch': 0.53}
{'eval_loss': 1.4946959018707275, 'eval_accuracy': 0.46, 'eval_runtime': 0.6686, 'eval_samples_per_second': 149.566, 'eval_steps_per_second': 10.47, 'epoch': 0.53}
{'loss': 1.5287, 'grad_norm': 25.119901657104492, 'learning_rate': 0.00018338888888888889, 'epoch': 0.6}
{'loss': 1.5879, 'grad_norm': 13.137285232543945, 'learning_rate': 0.0001806111111111111, 'epoch': 0.67}
{'eval_loss': 1.5240516662597656, 'eval_accuracy': 0.45, 'eval_runtime': 0.7254, 'eval_samples_per_second': 137.853, 'eval_steps_per_second': 9.65, 'epoch': 0.67}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 27%|██████████████████▉                                                    | 1000/3750 [02:33<06:33,  6.98it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 1.482, 'grad_norm': 23.41922950744629, 'learning_rate': 0.00017783333333333334, 'epoch': 0.73}
{'loss': 1.5073, 'grad_norm': 30.158838272094727, 'learning_rate': 0.00017505555555555558, 'epoch': 0.8}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 1.2974274158477783, 'eval_accuracy': 0.56, 'eval_runtime': 0.6711, 'eval_samples_per_second': 149.004, 'eval_steps_per_second': 10.43, 'epoch': 0.8}
{'loss': 1.4741, 'grad_norm': 28.817752838134766, 'learning_rate': 0.0001722777777777778, 'epoch': 0.87}
{'loss': 1.3698, 'grad_norm': 30.260589599609375, 'learning_rate': 0.00016950000000000003, 'epoch': 0.93}
{'eval_loss': 1.2843949794769287, 'eval_accuracy': 0.6, 'eval_runtime': 0.6783, 'eval_samples_per_second': 147.429, 'eval_steps_per_second': 10.32, 'epoch': 0.93}
{'loss': 1.4922, 'grad_norm': 29.527565002441406, 'learning_rate': 0.0001667222222222222, 'epoch': 1.0}
{'loss': 1.074, 'grad_norm': 33.16937255859375, 'learning_rate': 0.00016394444444444445, 'epoch': 1.07}
{'eval_loss': 1.2217507362365723, 'eval_accuracy': 0.52, 'eval_runtime': 0.7998, 'eval_samples_per_second': 125.029, 'eval_steps_per_second': 8.752, 'epoch': 1.07}
{'loss': 1.1476, 'grad_norm': 32.38313293457031, 'learning_rate': 0.00016116666666666666, 'epoch': 1.13}
{'loss': 1.0326, 'grad_norm': 25.73554039001465, 'learning_rate': 0.0001583888888888889, 'epoch': 1.2}
{'eval_loss': 1.3158843517303467, 'eval_accuracy': 0.51, 'eval_runtime': 0.6947, 'eval_samples_per_second': 143.949, 'eval_steps_per_second': 10.076, 'epoch': 1.2}
{'loss': 1.0056, 'grad_norm': 17.881227493286133, 'learning_rate': 0.00015561111111111111, 'epoch': 1.27}
{'loss': 1.1138, 'grad_norm': 37.513118743896484, 'learning_rate': 0.00015283333333333335, 'epoch': 1.33}
{'eval_loss': 1.6013020277023315, 'eval_accuracy': 0.47, 'eval_runtime': 0.6918, 'eval_samples_per_second': 144.549, 'eval_steps_per_second': 10.118, 'epoch': 1.33}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
 27%|███████████████████                                                    | 1007/3750 [02:34<08:39,  5.28it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 40%|████████████████████████████▍                                          | 1500/3750 [03:48<04:53,  7.67it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 1.0861, 'grad_norm': 25.883563995361328, 'learning_rate': 0.00015005555555555556, 'epoch': 1.4}
{'loss': 1.1025, 'grad_norm': 31.608951568603516, 'learning_rate': 0.00014727777777777778, 'epoch': 1.47}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 1.360520362854004, 'eval_accuracy': 0.54, 'eval_runtime': 0.6927, 'eval_samples_per_second': 144.358, 'eval_steps_per_second': 10.105, 'epoch': 1.47}
{'loss': 1.0474, 'grad_norm': 29.840993881225586, 'learning_rate': 0.00014450000000000002, 'epoch': 1.53}
{'loss': 1.0893, 'grad_norm': 21.628196716308594, 'learning_rate': 0.00014172222222222223, 'epoch': 1.6}
{'eval_loss': 1.5105178356170654, 'eval_accuracy': 0.52, 'eval_runtime': 0.6707, 'eval_samples_per_second': 149.095, 'eval_steps_per_second': 10.437, 'epoch': 1.6}
{'loss': 1.1248, 'grad_norm': 32.665470123291016, 'learning_rate': 0.00013894444444444447, 'epoch': 1.67}
{'loss': 1.023, 'grad_norm': 29.063453674316406, 'learning_rate': 0.00013616666666666665, 'epoch': 1.73}
{'eval_loss': 1.2225645780563354, 'eval_accuracy': 0.59, 'eval_runtime': 0.6709, 'eval_samples_per_second': 149.059, 'eval_steps_per_second': 10.434, 'epoch': 1.73}
{'loss': 1.0348, 'grad_norm': 32.507415771484375, 'learning_rate': 0.0001333888888888889, 'epoch': 1.8}
{'loss': 1.0651, 'grad_norm': 30.2075252532959, 'learning_rate': 0.0001306111111111111, 'epoch': 1.87}
{'eval_loss': 1.2081845998764038, 'eval_accuracy': 0.55, 'eval_runtime': 0.698, 'eval_samples_per_second': 143.269, 'eval_steps_per_second': 10.029, 'epoch': 1.87}
{'loss': 1.0341, 'grad_norm': 20.11696434020996, 'learning_rate': 0.00012783333333333334, 'epoch': 1.93}
{'loss': 1.0189, 'grad_norm': 25.123924255371094, 'learning_rate': 0.00012505555555555558, 'epoch': 2.0}
{'eval_loss': 1.220012903213501, 'eval_accuracy': 0.54, 'eval_runtime': 0.7108, 'eval_samples_per_second': 140.693, 'eval_steps_per_second': 9.848, 'epoch': 2.0}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
 40%|████████████████████████████▋                                          | 1517/3750 [03:51<05:22,  6.92it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 53%|█████████████████████████████████████▊                                 | 2000/3750 [05:04<04:06,  7.09it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 0.4582, 'grad_norm': 33.31497573852539, 'learning_rate': 0.0001222777777777778, 'epoch': 2.07}
{'loss': 0.6105, 'grad_norm': 39.85417175292969, 'learning_rate': 0.00011950000000000002, 'epoch': 2.13}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 1.4610276222229004, 'eval_accuracy': 0.57, 'eval_runtime': 0.6721, 'eval_samples_per_second': 148.797, 'eval_steps_per_second': 10.416, 'epoch': 2.13}
{'loss': 0.6477, 'grad_norm': 27.670827865600586, 'learning_rate': 0.00011672222222222222, 'epoch': 2.2}
{'loss': 0.5645, 'grad_norm': 92.6019515991211, 'learning_rate': 0.00011394444444444446, 'epoch': 2.27}
{'eval_loss': 1.4331248998641968, 'eval_accuracy': 0.65, 'eval_runtime': 0.6855, 'eval_samples_per_second': 145.882, 'eval_steps_per_second': 10.212, 'epoch': 2.27}
{'loss': 0.5664, 'grad_norm': 31.6771183013916, 'learning_rate': 0.00011116666666666667, 'epoch': 2.33}
{'loss': 0.6415, 'grad_norm': 40.51607131958008, 'learning_rate': 0.00010838888888888889, 'epoch': 2.4}
{'eval_loss': 1.100684404373169, 'eval_accuracy': 0.64, 'eval_runtime': 0.6796, 'eval_samples_per_second': 147.154, 'eval_steps_per_second': 10.301, 'epoch': 2.4}
{'loss': 0.526, 'grad_norm': 19.75987434387207, 'learning_rate': 0.0001056111111111111, 'epoch': 2.47}
{'loss': 0.5919, 'grad_norm': 4.711503982543945, 'learning_rate': 0.00010283333333333334, 'epoch': 2.53}
{'eval_loss': 1.499387264251709, 'eval_accuracy': 0.6, 'eval_runtime': 0.6818, 'eval_samples_per_second': 146.67, 'eval_steps_per_second': 10.267, 'epoch': 2.53}
{'loss': 0.5833, 'grad_norm': 31.189876556396484, 'learning_rate': 0.00010005555555555557, 'epoch': 2.6}
{'loss': 0.6822, 'grad_norm': 9.86080551147461, 'learning_rate': 9.727777777777778e-05, 'epoch': 2.67}
{'eval_loss': 1.255645751953125, 'eval_accuracy': 0.6, 'eval_runtime': 0.6848, 'eval_samples_per_second': 146.028, 'eval_steps_per_second': 10.222, 'epoch': 2.67}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
 54%|██████████████████████████████████████                                 | 2013/3750 [05:07<04:07,  7.02it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 67%|███████████████████████████████████████████████▎                       | 2500/3750 [06:17<02:22,  8.76it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 0.6387, 'grad_norm': 29.97233772277832, 'learning_rate': 9.449999999999999e-05, 'epoch': 2.73}
{'loss': 0.5757, 'grad_norm': 22.06802749633789, 'learning_rate': 9.172222222222223e-05, 'epoch': 2.8}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 1.1802992820739746, 'eval_accuracy': 0.66, 'eval_runtime': 0.6543, 'eval_samples_per_second': 152.839, 'eval_steps_per_second': 10.699, 'epoch': 2.8}
{'loss': 0.6131, 'grad_norm': 41.86504364013672, 'learning_rate': 8.894444444444446e-05, 'epoch': 2.87}
{'loss': 0.4987, 'grad_norm': 18.098955154418945, 'learning_rate': 8.616666666666667e-05, 'epoch': 2.93}
{'eval_loss': 1.156131386756897, 'eval_accuracy': 0.63, 'eval_runtime': 0.663, 'eval_samples_per_second': 150.837, 'eval_steps_per_second': 10.559, 'epoch': 2.93}
{'loss': 0.5955, 'grad_norm': 47.50310516357422, 'learning_rate': 8.33888888888889e-05, 'epoch': 3.0}
{'loss': 0.1873, 'grad_norm': 12.954606056213379, 'learning_rate': 8.061111111111112e-05, 'epoch': 3.07}
{'eval_loss': 1.553267002105713, 'eval_accuracy': 0.64, 'eval_runtime': 0.6822, 'eval_samples_per_second': 146.583, 'eval_steps_per_second': 10.261, 'epoch': 3.07}
{'loss': 0.2289, 'grad_norm': 53.69405746459961, 'learning_rate': 7.783333333333333e-05, 'epoch': 3.13}
{'loss': 0.2782, 'grad_norm': 30.708602905273438, 'learning_rate': 7.505555555555556e-05, 'epoch': 3.2}
{'eval_loss': 1.757430911064148, 'eval_accuracy': 0.66, 'eval_runtime': 0.6932, 'eval_samples_per_second': 144.249, 'eval_steps_per_second': 10.097, 'epoch': 3.2}
{'loss': 0.2432, 'grad_norm': 70.89020538330078, 'learning_rate': 7.227777777777778e-05, 'epoch': 3.27}
{'loss': 0.2201, 'grad_norm': 48.90500259399414, 'learning_rate': 6.95e-05, 'epoch': 3.33}
{'eval_loss': 1.9452259540557861, 'eval_accuracy': 0.63, 'eval_runtime': 0.6478, 'eval_samples_per_second': 154.362, 'eval_steps_per_second': 10.805, 'epoch': 3.33}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
 67%|███████████████████████████████████████████████▍                       | 2505/3750 [06:18<04:02,  5.14it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 80%|████████████████████████████████████████████████████████▊              | 3000/3750 [07:33<02:04,  6.01it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 0.1935, 'grad_norm': 27.620914459228516, 'learning_rate': 6.672222222222223e-05, 'epoch': 3.4}
{'loss': 0.2436, 'grad_norm': 0.12346795201301575, 'learning_rate': 6.394444444444445e-05, 'epoch': 3.47}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 2.2667486667633057, 'eval_accuracy': 0.59, 'eval_runtime': 0.6665, 'eval_samples_per_second': 150.028, 'eval_steps_per_second': 10.502, 'epoch': 3.47}
{'loss': 0.2626, 'grad_norm': 38.69963836669922, 'learning_rate': 6.116666666666667e-05, 'epoch': 3.53}
{'loss': 0.2639, 'grad_norm': 8.400895118713379, 'learning_rate': 5.838888888888889e-05, 'epoch': 3.6}
{'eval_loss': 1.930519700050354, 'eval_accuracy': 0.65, 'eval_runtime': 0.6791, 'eval_samples_per_second': 147.243, 'eval_steps_per_second': 10.307, 'epoch': 3.6}
{'loss': 0.2037, 'grad_norm': 1.4646550416946411, 'learning_rate': 5.5611111111111116e-05, 'epoch': 3.67}
{'loss': 0.2443, 'grad_norm': 0.3216257393360138, 'learning_rate': 5.2833333333333335e-05, 'epoch': 3.73}
{'eval_loss': 1.9781090021133423, 'eval_accuracy': 0.66, 'eval_runtime': 0.6648, 'eval_samples_per_second': 150.415, 'eval_steps_per_second': 10.529, 'epoch': 3.73}
{'loss': 0.2104, 'grad_norm': 56.847496032714844, 'learning_rate': 5.005555555555555e-05, 'epoch': 3.8}
{'loss': 0.3045, 'grad_norm': 80.95793151855469, 'learning_rate': 4.727777777777778e-05, 'epoch': 3.87}
{'eval_loss': 2.044421434402466, 'eval_accuracy': 0.67, 'eval_runtime': 0.6759, 'eval_samples_per_second': 147.961, 'eval_steps_per_second': 10.357, 'epoch': 3.87}
{'loss': 0.2764, 'grad_norm': 31.187915802001953, 'learning_rate': 4.4500000000000004e-05, 'epoch': 3.93}
{'loss': 0.1931, 'grad_norm': 5.667616844177246, 'learning_rate': 4.172222222222222e-05, 'epoch': 4.0}
{'eval_loss': 1.7596726417541504, 'eval_accuracy': 0.67, 'eval_runtime': 0.9124, 'eval_samples_per_second': 109.604, 'eval_steps_per_second': 7.672, 'epoch': 4.0}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
 80%|█████████████████████████████████████████████████████████▏             | 3018/3750 [07:36<01:47,  6.81it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
 93%|██████████████████████████████████████████████████████████████████▎    | 3500/3750 [08:51<00:36,  6.92it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 0.0339, 'grad_norm': 29.60611343383789, 'learning_rate': 3.894444444444444e-05, 'epoch': 4.07}
{'loss': 0.0868, 'grad_norm': 0.4760096073150635, 'learning_rate': 3.6166666666666674e-05, 'epoch': 4.13}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 1.8389792442321777, 'eval_accuracy': 0.68, 'eval_runtime': 0.7427, 'eval_samples_per_second': 134.644, 'eval_steps_per_second': 9.425, 'epoch': 4.13}
{'loss': 0.0377, 'grad_norm': 0.08834750205278397, 'learning_rate': 3.338888888888889e-05, 'epoch': 4.2}
{'loss': 0.0347, 'grad_norm': 111.91810607910156, 'learning_rate': 3.061111111111111e-05, 'epoch': 4.27}
{'eval_loss': 2.0000782012939453, 'eval_accuracy': 0.7, 'eval_runtime': 0.6874, 'eval_samples_per_second': 145.478, 'eval_steps_per_second': 10.183, 'epoch': 4.27}
{'loss': 0.057, 'grad_norm': 0.3670688569545746, 'learning_rate': 2.7833333333333333e-05, 'epoch': 4.33}
{'loss': 0.045, 'grad_norm': 145.6775360107422, 'learning_rate': 2.5055555555555555e-05, 'epoch': 4.4}
{'eval_loss': 2.216421604156494, 'eval_accuracy': 0.67, 'eval_runtime': 0.8011, 'eval_samples_per_second': 124.827, 'eval_steps_per_second': 8.738, 'epoch': 4.4}
{'loss': 0.0122, 'grad_norm': 0.012273316271603107, 'learning_rate': 2.2277777777777778e-05, 'epoch': 4.47}
{'loss': 0.031, 'grad_norm': 0.01789853349328041, 'learning_rate': 1.9500000000000003e-05, 'epoch': 4.53}
{'eval_loss': 1.6742966175079346, 'eval_accuracy': 0.72, 'eval_runtime': 0.6772, 'eval_samples_per_second': 147.678, 'eval_steps_per_second': 10.337, 'epoch': 4.53}
{'loss': 0.0107, 'grad_norm': 0.37206485867500305, 'learning_rate': 1.6722222222222222e-05, 'epoch': 4.6}
{'loss': 0.0286, 'grad_norm': 35.07769775390625, 'learning_rate': 1.3944444444444446e-05, 'epoch': 4.67}
{'eval_loss': 1.948327898979187, 'eval_accuracy': 0.71, 'eval_runtime': 0.8526, 'eval_samples_per_second': 117.288, 'eval_steps_per_second': 8.21, 'epoch': 4.67}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
 94%|██████████████████████████████████████████████████████████████████▋    | 3520/3750 [08:54<00:32,  7.01it/s]D:\MLLMs\MLLM\.venv\Lib\site-packages\torch\nn\modules\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\aten\src\ATen\native\cudnn\Conv_v8.cpp:919.)
  return F.conv1d(input, weight, bias, self.stride,
100%|███████████████████████████████████████████████████████████████████████| 3750/3750 [09:29<00:00,  9.36it/s]CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
{'loss': 0.0292, 'grad_norm': 0.0003547025262378156, 'learning_rate': 1.1166666666666668e-05, 'epoch': 4.73}
{'loss': 0.0546, 'grad_norm': 0.7164060473442078, 'learning_rate': 8.38888888888889e-06, 'epoch': 4.8}
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
{'eval_loss': 1.9187091588974, 'eval_accuracy': 0.71, 'eval_runtime': 0.7105, 'eval_samples_per_second': 140.742, 'eval_steps_per_second': 9.852, 'epoch': 4.8}
{'loss': 0.0484, 'grad_norm': 0.0004826783260796219, 'learning_rate': 5.611111111111112e-06, 'epoch': 4.87}
{'loss': 0.0192, 'grad_norm': 0.004724877420812845, 'learning_rate': 2.8333333333333335e-06, 'epoch': 4.93}
{'eval_loss': 1.9025999307632446, 'eval_accuracy': 0.71, 'eval_runtime': 0.7106, 'eval_samples_per_second': 140.734, 'eval_steps_per_second': 9.851, 'epoch': 4.93}
{'loss': 0.012, 'grad_norm': 0.025780992582440376, 'learning_rate': 5.555555555555556e-08, 'epoch': 5.0}
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
100%|███████████████████████████████████████████████████████████████████████| 3750/3750 [09:29<00:00,  6.58it/s]
{'train_runtime': 572.4203, 'train_samples_per_second': 52.409, 'train_steps_per_second': 6.551, 'train_loss': 0.7602950456460317, 'epoch': 5.0}
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
CorenetToHFPretrainedModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
训练完成！
